{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShayHav/MachineLearning/blob/main/Ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ex1 - Unsupervised learning**"
      ],
      "metadata": {
        "id": "djcj7z3isEoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Names and IDs\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n"
      ],
      "metadata": {
        "id": "bbLvYfOMnaOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignemnt you will practice unsupervised methods we saw in class, and specifically running K-means and visualizing the data using PCA.\n",
        "\n",
        "In this assignment you will learn a few more things:\n",
        "\n",
        "1.   Load local files\n",
        "2.   Load data from Kaggle\n",
        "3. Use Scikit-learn K-means\n",
        "4. Use Scikit-learn PCA\n",
        "5. Some visulaization\n",
        "6. Evaluate the performance of the clustering using Elbow methods, Siouhette analysis and accuracy (as we have true labels)\n",
        "\n",
        "Note:\n",
        "* Read the complete task before implementing.\n",
        "* Reuse code, write functions."
      ],
      "metadata": {
        "id": "vpmlOOaKWUHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import All Packages\n",
        "Add all imports needed for this notebook to run"
      ],
      "metadata": {
        "id": "SmSdJm9coKpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "ZAw8GGhYT1gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Clustering And Dimension Reduction"
      ],
      "metadata": {
        "id": "y_-HIZ7Rnkfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise you will cluster fake news using `k-means` and visualize the clustering using PCA."
      ],
      "metadata": {
        "id": "kQKN1XWKtGu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the Fake News Dataset from Kaggle**\n",
        "\n",
        "Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n",
        "\n",
        "Then run the cell below and click the upload button to upload kaggle.json to your Colab runtime.\n",
        "\n",
        "After uploading the kaggle.json the fake news dataset will be copy to the enviroment in the '/content' directory. You will see the two files 'Fake.csv' and 'True.csv'.\n",
        "\n",
        "For more about the dataset you can read [here](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset)."
      ],
      "metadata": {
        "id": "cjvrUWutYAQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# upload kaggle.json file using user prompt\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# download the dataset\n",
        "!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset\n",
        "\n",
        "# extract the files\n",
        "!unzip '/content/fake-and-real-news-dataset.zip'"
      ],
      "metadata": {
        "id": "pt0gDVr_YGvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Read the csv files and create one single dataframe (5 points)\n",
        "\n",
        "*   Create a dataframe which is the join of the two files 'Fake.csv' and 'True.csv'.\n",
        "*   Extract the 'text' column from each dataframe (droping title, subject and date columns).\n",
        "*   Create a single dataframe containing a text column and a label column (fake=0, real=1)."
      ],
      "metadata": {
        "id": "sIT7GQbLo9-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here\n",
        "# Example for reading one file. It will work if the previous step was successful.\n",
        "face_df = pd.read_csv('/content/Fake.csv')"
      ],
      "metadata": {
        "id": "tYvY12rep0sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cluster the samples into 2 clusters (real and fake) (15 points)\n",
        "\n",
        "*   Generate TF-IDF features by applying the TfidfVectorizer preprocessor using 1000 features (`max_features=1000`) and remove English stop words.\n",
        "* Scale the data.\n",
        "*    Apply k-Means algorithm on the TF-IDF features using n_clusters=2."
      ],
      "metadata": {
        "id": "-Wp5qcYwqBxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "gIpApLQvqB-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualize using scatter plot (15 points)\n",
        "The data is high dimensional, so for visualization purpose, we will perform a dimensionality reduction using PCA.\n",
        "\n",
        "* Apply PCA\n",
        "*   Visualize the clustering in 2d using first two PCs.\n",
        "*   Visualize the clustering in 3d using first three PCs.\n",
        "\n",
        "Notes:\n",
        "\n",
        "*   In clustering visualization it's important to also visualize the centroids.\n",
        "* Visualize using matplotlib scatter function. It can be used to plot 2D or 3D scatter plots.\n",
        "* Color the points according to the true labels."
      ],
      "metadata": {
        "id": "d4hK3vpTtRTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "DUhtdsvGtlJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Performance evaluation (15 points)\n",
        "### How did our clustering perform against the real labels?\n",
        "\n",
        "We do have the true lables (fake/real), but we don't know which cluster correspond to which label. Therefore, we check the two options:\n",
        "\n",
        "*   Define cluster 1 as fake and cluster 2 as real. What is the accuracy?\n",
        "*   Define cluster 1 as true and cluster 2 as fake. What is the accuracy?"
      ],
      "metadata": {
        "id": "ELEMd4WFFTwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "hVVyjDIoJKeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Find optimal `k` (10 points)\n",
        "What is the best k for clustering?\n",
        "\n",
        "* Cluster using a range of `k` (up to 20) and compare the SSD and the Silhouette values for every k.\n",
        "* Plot SSD vs. k and Silhouette score vs. k.\n",
        "\n",
        "Notes:\n",
        "* You can get the SSD of a clustering using the `inertia_` attribute of the model.\n",
        "* Silhouette score using `silhouette_score` function from `sklearn.metrics`. This function accept the model and the data.\n",
        "* Computing Silhouette may takes long time. Estimate the Silhouette using a sample of 300 samples uisng the argument `sample_size=300`."
      ],
      "metadata": {
        "id": "Go3Jx05Wcsr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement here"
      ],
      "metadata": {
        "id": "DvGLxRHGWPop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. What is the optimal k for clustering? (10 points)\n",
        "\n",
        "* Explain.\n",
        "* If optimal k!=2 what can be a good explanation for this?"
      ],
      "metadata": {
        "id": "7WcPTIareSCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer here"
      ],
      "metadata": {
        "id": "k3s2biB6uyVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. PCA then k-means (10 points)\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "This time, lets try to change the order.\n",
        "1. Generate TF-IDF 1000 features\n",
        "2. Run PCA (using all dimenssions)\n",
        "3. Run k-means\n",
        "4. Plot 2D and 3D scatter plots\n",
        "5. Estimate the accuracy according to true labels.\n",
        "6. Explain how is it compared to the previous approach, where clustering is performed w/o PCA.\n",
        "\n",
        "Note:\n",
        "* When you compute the PCA, don't limit to first PCs, but use all of them."
      ],
      "metadata": {
        "id": "g1Cuo2LNR3R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Answer \"\"\""
      ],
      "metadata": {
        "id": "NJf98Fx9WCce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST clustering (10 points)\n",
        "Redo the same analysis, but this time using the MNIST data set. Notice that this time there are actually 10 'true' clusters.\n",
        "\n",
        "1. What is the accuracy of the clustering when using k=10? \\\\\n",
        "   * When for computing the accuracy of 10 classes, first you need to define what is the label of each cluster. Do that by majority votes. In theory, you may get two or more clusters with the same labels. We will ignore that for now. Meaning that you don't need to bother in case there are two clusters with the same label according to the majority vote. Simply count what is the fraction of 'other' digits in each cluster.\n",
        "2. What is the optimal k?\n",
        "3. How do the results changes if you first run PCA?"
      ],
      "metadata": {
        "id": "JiYp9sP0apoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute projection (10 points)\n",
        "**Notice:** No code required in this section.\n",
        "\n",
        "Given the next PCA projection matrix\n",
        "$\\begin{pmatrix}\n",
        "1 & 1\\\\\n",
        "2 & -1\n",
        "\\end{pmatrix}$\n",
        "And the correspoding egienvalues\n",
        "$(5, -1)$\n",
        "\n",
        "Compute the projection to one dimension of the next two vectors:\n",
        "\\begin{pmatrix}\n",
        "1 & 3\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "3 & 7\n",
        "\\end{pmatrix}"
      ],
      "metadata": {
        "id": "3ft1JUt39-4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer here and show your computations (no code)"
      ],
      "metadata": {
        "id": "VCQQ0Jzxapo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your answers here*"
      ],
      "metadata": {
        "id": "Fzv4mYUkvqMB"
      }
    }
  ]
}